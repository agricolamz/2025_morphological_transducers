# Метрики качества

Как и в остальных инструментах машинного обучения при работе над морфологическими анализаторами нам нужна некоторая мера, которая покажет качество получившейся модели. Морфологические анализаторы могут делать это на материале некоторого корпуса. В качестве игрушечного примера мы рассмотрим следующий корпус, содержащий порошок пользователя Кисычев:

```{{shell}}
$ cat corpus.txt
```

```{python}
!cat examples/08_corpus.txt
```

Для целей данного занятия мы рассмотрим следующий игрушечный трансдьюсер:

```{{shell}}
$ cat example.lexd
```

```{python}
!cat examples/08_example.lexd
```

Скомпилируем наш трансдьюсер:

```{{shell}}
$ lexd example.lexd | hfst-txt2fst | hfst-invert | hfst-fst2fst -O -o analyzer.hfstol
```

```{python}
!lexd examples/08_example.lexd | hfst-txt2fst | hfst-invert | hfst-fst2fst -O -o examples/analyzer.hfstol
```

```{{shell}}
$ cat corpus.txt | hfst-proc -C analyzer.hfstol
```

```{python}
!cat examples/08_corpus.txt | hfst-proc -C examples/analyzer.hfstol
```

Сразу отметим недостатки данного трансдьюсера:

- он не разбирает глаголы;
- он предложит неправильный разбор для синтагмы `о россии`, приписав слову *россии* родительный падеж вместо предложного;
- все существительные мужского рода будут иметь лишний разбор, так как в единственном числе не различают именительный и винительный падежи.

## Покрытие

Покрытие (coverage, naïve coverage) --- это простейший способ оценить качество трансдьюсера. Его высчитывают как долю форм, которая разбирается трансдьюсером. Посчитаем сколько токенов всего в корпусе:

```{{shell}}
$ cat corpus.txt | wc -w
```

```{python}
!cat examples/08_corpus.txt | wc -w
```

Посчитаем, сколько токенов не разбирает трансдьюсер:

```{{shell}}
$ cat corpus.txt | hfst-proc -C analyzer.hfstol | grep -c "*"
```

```{python}
!cat examples/08_corpus.txt | hfst-proc -C examples/analyzer.hfstol | grep -c "*"
```

Таким образом, покрытие нашего трансдьюсера приблизительно соответствует $\frac{17-6}{17} \approx 0.65$. Не стоит сильно доверять этой мере, так как она совершенно не учитывает качество разбора, таким образом завышая качество.

## Точность и полнота

Точность (precision) и полнота (recall) --- метрики, используемые при оценке большей части алгоритмов машинного обучения. Иногда их используют сами по себе, а иногда в виде производных метрик, например F-меры. 

<формулы>

В применении к морфологическому анализу, данные метрики должны учитывать качество разбора, а это значит, что нам нужно завести золотой стандарт.

## Сложности при подсчете метрик

- сегментатор
- разный порядок тегов
- неточные совпадения: основа; основа + часть речи

```{python}
!rm -f examples/*.hfstol
```
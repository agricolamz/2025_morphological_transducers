[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Конечные автоматы в морфологическом анализе 2024/2025",
    "section": "",
    "text": "Введение\nДанные материалы являются конспектом курса Т. Б. Казаковой и Г. А. Мороза ‘Конечные автоматы в морфологическом анализе’ 2024–2025. Данный курс предоставляет углубленное изучение применения конечных автоматов в морфологическом анализе. Конечные автоматы используются для моделирования морфологии языков, особенно малоресурсных. Курс охватывает основные этапы создания морфологического анализатора в системе lexd и twol, проверку его на корпусах, взвешивание трансдьюсера для дизамбигуации. В качестве иллюстративного материала будут использоваться лингвистические задачи и реальные примеры из практики преподавателей. В нашем курсе мы стараемся предложить стратегии компьютерного правилого моделирвания морфологических и морфонологически проблем, стараясь охватить явления интересные с точки зрения теоретической лингвистики.\nВ курсе будет 6 домашних заданий и экзамен. Все домашние задания имеют одинаковый вес. Экзамен весит 0.4. За курс предусмотрен автомат, если студента устраивает накопленная оценка.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#домашние-задания",
    "href": "index.html#домашние-задания",
    "title": "Конечные автоматы в морфологическом анализе 2024/2025",
    "section": "Домашние задания",
    "text": "Домашние задания\n\nСсылка на первое домашнее задание. Дедлайн: 27 февраля 23:59.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "01_introduction_to_transducers.html",
    "href": "01_introduction_to_transducers.html",
    "title": "1  Автоматический морфологический анализ",
    "section": "",
    "text": "1.1 Приведение к основе (stemming)\nМорфологический анализ, как его обычно видят лингвисты, обычно включает в себя несколько вещей:\nВ зависимости от целей люди делают акцент на разные аспекты морфологического анализа. Для многих NLP задач полезным является приведение к начальной форме, лингвистический корпусной анализ практически невозможен без заранее определенных морфологических форм, и все три необходимы для представления языкового материала в научной работе. Также стоит помнить, что для разных задач могут быть важны разные категории, например, лингвисты, когда приводят примеры, редко перечисляют несловоизменительную информацию (например, род для существительных), которая может быть важна в каких-то задачах.\nДостаточно широкое применение в ранюю эпоху NLP получили методы, которые позволяют привести словоформы к основе или квазиоснове. Эта процедура помогала уменьшить разнообразие форм в тексте, что облегчало поиск и извлечение информации. В работе (Singh и Gupta 2017) приводится целая классификация стемеров:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Автоматический морфологический анализ</span>"
    ]
  },
  {
    "objectID": "01_introduction_to_transducers.html#много-данных",
    "href": "01_introduction_to_transducers.html#много-данных",
    "title": "1  Автоматический морфологический анализ",
    "section": "1.2 Много данных",
    "text": "1.2 Много данных\nОбычно, если много данных, люди используют нейросети. Для морфологического анализа русского языка их использовали в следующих работах (Arefyev, Gratsianova, и Popov 2018; Sorokin и Kravtsova 2018; Bolshakova и Sapin 2019a, 2019b, 2020; Garipov, Morozov, и Glazkova 2023). Используются разные архитектуры:\n\ncвёрточные нейронные сеть (convolutional neural network, CNN);\nдеревья решения с градиентным бустингом (decision trees with gradient boosting);\nдвунаправленная длинная цепь элементов краткосрочной памяти (Biderectional long short-term memory network, Bi-LSTM);\nи другие.\n\nДругой важный проект, который можно упомянуть в этом разделе: UDPipe — проект, основанный на размеченных в формате Universal Dependencies трибанках большого количества языков (Straka 2018). Отметим, что их задача амбициознее: они строят модель, совмещающую морфологический парсер и синтаксический парсер дерева зависимостей. Внутри: длинная цепь элементов краткосрочной памяти (LSTM), которая работает на основе векторного представления слов.\nТакже стоит упомянуть проект Morfessor, в котором используют скрытые марковские цепи (HMM) (Grönroos и др. 2014).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Автоматический морфологический анализ</span>"
    ]
  },
  {
    "objectID": "01_introduction_to_transducers.html#другие-правиловые-подходы",
    "href": "01_introduction_to_transducers.html#другие-правиловые-подходы",
    "title": "1  Автоматический морфологический анализ",
    "section": "1.3 Другие правиловые подходы",
    "text": "1.3 Другие правиловые подходы\nСтоит отметить, что существуют не основанные на трансдьюсерах правиловые подходы, например,\n\nпроект uniparser-morph Тимофея Архангельского (Архангельский 2012);\nнечто, что работает в SIL Fieldworks;\nмножество узконаправленных парсеров, написанных для конкертных языков.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Автоматический морфологический анализ</span>"
    ]
  },
  {
    "objectID": "01_introduction_to_transducers.html#от-автоматов-к-морфологическим-трансдьюсерам",
    "href": "01_introduction_to_transducers.html#от-автоматов-к-морфологическим-трансдьюсерам",
    "title": "1  Автоматический морфологический анализ",
    "section": "1.4 От автоматов к морфологическим трансдьюсерам",
    "text": "1.4 От автоматов к морфологическим трансдьюсерам\n\n1.4.1 Конечные автоматы\nТеория автоматов — это дисциплина на стыке математики и компьютерных наук, которая появилась в XX веке. Первые конечных автоматов были предложены в работах (Mealy 1955; Moore 1956). Данный раздел основан на первой главе из (Beesley и Karttunen 2003: 1–42).\nПод автоматами мы понимаем абстрактные машины, которые принимают разные состояния, а изменение состояний вызывается некоторым действием:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nМы не будем давать формального определения конечных автоматов, а перечислим его состовляющие:\n\nалфавит, который автомат понимает;\nконечное количество состояний;\nпереходы между состояниями;\nодно начальное состояние (часто обозначют нулем);\nнабор конечных состояний (часто обозначают двойным кружочком).\n\nКонечные автоматы можно использовать для побуквенной верефикации поданных на вход слов:\n\n\n\n\n\n\n\n\n\nЕсли программа смогла пройти путь до конечного состояния (обозначен двойным кружочком), значит операция завершилась успехом, в остальных случаях — неудачей. Обычно путь, ведущий к неудаче, не отображают.\n\n\n\n\n\n\n\n\n\nМожно сделать так, чтобы автомат верефицировал несколько слов:\n\n\n\n\n\n\n\n\n\nПолученный автомат можно оптимизировать, так, чтобы там было меньше узлов, а задачи он решал те же самые:\n\n\n\n\n\n\n\n\n\nРазличают детерминированные и недетерминированные конечные автоматы. Последние отличаются от первых тем, что не выполняют одно из следующих требований:\n\nлюбой переход единственным образом определяется по текущему состоянию и входному символу;\nчтение входного символа требуется для каждого изменения состояния.\n\nСуществуют математические работы, доказывающие, что для любого регулярного языка существует детерминированный конечный автомат с наименьшим возможным числом состояний. Такой автомат единственен с точностью до изоморфизма. Нам это важно как знание, что наши лингвистические автоматы можно оптимизировать.\nВажно отметить, что в данном разделе наши автоматы были представлены диаграммами состояний, однако автомат можно представить и в виде таблицы переходов, в которой каждая строка соотвествует одному состоянию, а столбцу допустимый входной символ (и выходной, если речь о трансдьюсерах, см. ниже). Данный формат еще называют ATT. Дополнительный столбец может соответсвовать столбцу весов.\n\n\n\nисходное состояние\nследующее состояние\nвходной символ\n\n\n\n\n0\n1\nс\n\n\n1\n2\nл\n\n\n2\n3\nо\n\n\n3\n4\nн\n\n\n0\n5\nу\n\n\n5\n1\nк\n\n\n0\n6\nк\n\n\n6\n1\nу\n\n\n\nТо же самое, записанное в формате БНФ (Бэкусовская нормальная форма или Бэкуса-Науэра форма):\n0::с1|у5|к6\n1::л2\n2::о3\n3::н4  \n5::к1\n6::у1\n\n\n1.4.2 Трансдьюсеры\nВсё, что мы рассмотрели до этого момента, позволяло лишь принимать/отвергать слова, поданные на вход. Если мы немного усложним автомат, добавив в него еще выходной алфавит, то мы получим трансдьюсер (в русской википедии они названы конечными автоматами с выходом). Мы будем использовать обновленную нотацию: то, что представлено на вход, мы пишем слева от двоеточия, а то, что получается на выходе — справа.\n\n\n\n\n\n\n\n\n\nВ добавку к проверке наших слов, которое обеспечивалось конечными автоматами, мы получаем нечто на выходе. Пока в нашем примере на выходе получается то же самое, что на входе. Пустую строку принято обозначать греческой буквой эпсилон: ε. Таким образом мы можем представить трансдьюсер, который, наконец-то, делает некоторый морфологический анализ.\n\n\n\n\n\n\n\n\n\n\n\n\nвход\nвыход\n\n\n\n\nслон\nслон&lt;n&gt;&lt;nom&gt;&lt;sg&gt;\n\n\nслоном\nслон&lt;n&gt;&lt;ins&gt;&lt;sg&gt;\n\n\nуклон\nуклон&lt;n&gt;&lt;nom&gt;&lt;sg&gt;\n\n\nуклоном\nуклон&lt;n&gt;&lt;ins&gt;&lt;sg&gt;\n\n\nкулон\nкулон&lt;n&gt;&lt;nom&gt;&lt;sg&gt;\n\n\nкулоном\nкулон&lt;n&gt;&lt;ins&gt;&lt;sg&gt;\n\n\n\nВажно также отметить, что вообще-то не обязательно что-то делать на каждом этапе. Можно сделать трансдьюсер, который по духу будет автоматом, но дойдя до некоторого состояния, будет выдавать лэйбл.\n\n\n\n\n\n\n\n\n\nЛингвистические трансдьюсеры можно использовать для\n\nморфологического анализа\nтранслитерации/транскрипции\nпредиктивного ввода\nв системах проверки правописания\nв системах автоматического перевода близкородственных языков\nв системах распознавания речи\nи др.\n\nС трансдьюсерами можно делать много разных операций:\n\nобъединение (конечные и начальные состояния совпадают, все промежуточные сохраняются);\nконкатенация (конечное состояние одного трансдьюсера становится начальным состоянием другого);\nпересечение (в особых случаях;\nвычитание (в особых случаях);\nкомпозиция (обсудим ниже).\n\nКомпозиция трансдьюсеров аналогична функциям join для таблиц. После композиции трансдьюсера &lt;x, y&gt; и &lt;y, z&gt; получается новый трансдьюсер &lt;x, z&gt;.\n\n\n\n\n\n\n\n\n\nИменно при помощи композиции трансдьюсеров можно объединять трансдьюсеры с разными “целями”: например, трансдьюсер, который приводит к начальной форме и пишет морфологические теги, с трансдьюсером, который переводит основы. Кроме того, бывают взвешенные трансдьюсеры, в которых каждому переходу в новое состояние приписывается некоторый вес. Такой трансдьюсер позволяет не просто получать возможные варианты, но и ранжировать их, что важно при создании спеллчекеров.\nЗакончим перечислением преимуществ трансдьюсеров. Оптимизированный трансдьюсер оптимален с точки зрения объема требуемой памяти для хранения и скорости поиска. Композиция трансдьюсеров открывает большой и богатый мир, позволяет создавать и комбинировать между собой очень разные инструменты.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Автоматический морфологический анализ</span>"
    ]
  },
  {
    "objectID": "01_introduction_to_transducers.html#проблемы-моделирования-морфологии-языка",
    "href": "01_introduction_to_transducers.html#проблемы-моделирования-морфологии-языка",
    "title": "1  Автоматический морфологический анализ",
    "section": "1.5 Проблемы моделирования морфологии языка",
    "text": "1.5 Проблемы моделирования морфологии языка\n\nПроблема описаний:\n\nнеполнота: то, что исследователи посчитали достаточным для грамматического описания, может быть недостаточно для моделирования; для некоторого языка может быть доступно грамматическое описание, но отсутствовать словарь и наоборот; словарь может не содержать информации про словоизменительный класс каких-то единиц, которые различаются в грамматическом описании.\nпротиворечивые источники: грамматические описания могут противоречить друг другу; грамматические описания могут противоречить словарям\n\nПроблема вариативности:\n\nидиолектная\nдиалектная\nсвязанная с какими-нибудь социолингвистическими параметрами (в первую очередь такие как пол и возраст, но можно придумать и другие)\n\nПроблема неоднозначности (особенно перекошенной частотно):\n\nлексической\nморфологическая\nсинтаксическая\n…\n\nПроблема идиом и суплетивизма: в какой форме стоит глагол в ругательстве ** твою мать?\nПроблема циклов, возникающих при словообразовании:\n\nслуга (N) &gt; служить (V) &gt; услужить (V) &gt; услужение (N), услуга (N)1\n\nПроблема морфологической сложности: для языков с бедной морфологией проще строить прсотой правиловый морфологический парсер, а не трансдьюсер\nТехнические сложности: весь софт для создания морфологических трансдьюсеров пишут под Linux, за исключением может быть пакета hfst-dev для Python\nНе так просто работать совместно над одним проектом, чаще всего лучше иметь двух людей — специалиста по языку, и специалиста по трансдьюсерам.\n\nСмотрите еще обсуждения на FST в работе (Wintner 2008).\n\n\n\n\nArefyev, N. V., T. Y. Gratsianova, и K. P. Popov. 2018. «Morphological segmentation with sequence to sequence neural network». В KКомпьютерная лингвистика и интеллектуальные технологии, 85–95.\n\n\nBeesley, K. R., и L. Karttunen. 2003. Finite State Morphology: Xerox tools and techniques. Stanford: Center for Study of Language Information.\n\n\nBolshakova, E. I., и A. S. Sapin. 2019a. «Bi-LSTM model for morpheme segmentation of Russian words». В Artificial Intelligence and Natural Language: 8th Conference, AINL 2019, Tartu, Estonia, November 20–22, 2019, Proceedings 8, 151–60. Springer.\n\n\n———. 2019b. «Comparing models of morpheme analysis for Russian words based on machine learning». В Компьютерная лингвистика и интеллектуальные технологии, 104–13.\n\n\n———. 2020. «An Experimental Study of Neural Morpheme Segmentation Models for Russian Word Forms.» В CMCL, 79–89.\n\n\nGaripov, T., D. Morozov, и A. Glazkova. 2023. «Generalization ability of CNN-based Morpheme Segmentation». В 2023 Ivannikov Ispras Open Conference (ISPRAS), 58–62. IEEE.\n\n\nGrönroos, S.-A., S. Virpioja, P. Smit, и M. Kurimo. 2014. «Morfessor FlatCat: An HMM-based method for unsupervised and semi-supervised learning of morphology». В Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, 1177–85.\n\n\nMealy, G. H. 1955. «A method for synthesizing sequential circuits». The Bell System Technical Journal 34 (5): 1045–79.\n\n\nMoore, E. F. 1956. «Gedanken-experiments on sequential machines». Automata studies 34: 129–53.\n\n\nSingh, J., и V. Gupta. 2017. «A systematic review of text stemming techniques». Artificial Intelligence Review 48: 157–217.\n\n\nSorokin, Alexey, и Anastasia Kravtsova. 2018. «Deep convolutional networks for supervised morpheme segmentation of Russian language». В Artificial Intelligence and Natural Language: 7th International Conference, AINL 2018, St. Petersburg, Russia, October 17–19, 2018, Proceedings 7, 3–10. Springer.\n\n\nStraka, Milan. 2018. «UDPipe 2.0 prototype at CoNLL 2018 UD shared task». В Proceedings of the CoNLL 2018 shared task: Multilingual parsing from raw text to universal dependencies, 197–207.\n\n\nWintner, S. 2008. «Strengths and weaknesses of finite-state technology: a case study in morphological grammar development». Natural Language Engineering 14 (4): 457–69.\n\n\nАрхангельский, Т. А. 2012. «Принципы построения морфологического парсера для разноструктурных языков». Phdthesis, Московский государственный университет им. М. В. Ломоносова.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Автоматический морфологический анализ</span>"
    ]
  },
  {
    "objectID": "01_introduction_to_transducers.html#footnotes",
    "href": "01_introduction_to_transducers.html#footnotes",
    "title": "1  Автоматический морфологический анализ",
    "section": "",
    "text": "Я лишь предполагаю такую историческую деревацию, возможно, этимологии этих слов таят в себе значительно более сложную историю.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Автоматический морфологический анализ</span>"
    ]
  },
  {
    "objectID": "02_introduction_to_lexd.html",
    "href": "02_introduction_to_lexd.html",
    "title": "2  Введение в lexd: морфология",
    "section": "",
    "text": "2.1 Техническое введение\nВ данном разделе мы обсуждаем синтаксис программы lexd (Swanson и Howell 2021). Данная программа работает в связке\nЭто консольная программа, работающая на юниксоподобных системах. Чтобы избежать сложностей на начальных этапах курса, мы решили вначале познакомиться с синтаксисом lexd и попробовать описывать разные языковые явления, не затрудняя всех установкой и запуском у себя на компьютере. В связи с этим мы предлагаем выучить следующие четыре команды, которые будут работать на операционных системах Linux, основанных на Debian/Ubuntu, и в Google Colab:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Введение в `lexd`: морфология</span>"
    ]
  },
  {
    "objectID": "02_introduction_to_lexd.html#техническое-введение",
    "href": "02_introduction_to_lexd.html#техническое-введение",
    "title": "2  Введение в lexd: морфология",
    "section": "",
    "text": "с бесплатным програмным обеспечением с открытым исходным кодом Helsinki Finite-State Tookit hfst (Lindén и др. 2011);\nаналогичным инструментом от Apertium lttoolbox (Ortiz Rojas, Forcada, и Ramı́rez Sánchez 2005).\n\n\n\nскачиваем инструкции для установки lexd и hfst и дальнейшей работы с ними, записанные в простом текстовом файле, которые можно прочитать, если открыть ссылку из команды. Команда make запускает установку. Для того, чтобы это работало в Google Colab нужно перед командой нужно поставить восклицательный знак: !curl .... Знак доллара означает, что дальше следует команда командной строки, не надо его никуда копировать.\n\n```{shell}\n$ curl -s https://raw.githubusercontent.com/agricolamz/2025_morphological_transducers/refs/heads/main/task_tests/Makefile -o Makefile; make\n```\n\nдальше мы ожидаем, что вы создадите в коллабе или у себя на компьютере (если у вас Linux), файл с названием task.lexd. В Google Colab для этого достаточно вставить первой строкой кодового блока %%writefile task.lexd. Вот пример такого файла:\n\n```{lexd}\nPATTERNS\nVerbRoot VerbInfl\n\nLEXICON VerbRoot\nsing&lt;v&gt;:sing\nwalk&lt;v&gt;:walk\ndance&lt;v&gt;:dance\n\nLEXICON VerbInfl\n&lt;pres&gt;:\n&lt;pres&gt;&lt;3&gt;&lt;sg&gt;:s\n```\n\nПосле того, как вы установили нужные программы и создали файл, можно посмотреть формы и разборы, которые генерируются трансдьюсером. Это можно сделать следующей командой (не забудьте поставить восклицательный знак перед make в Google Colab):\n\n```{shell}\n$ make forms\n\nsing&lt;v&gt;&lt;pres&gt;:sing\nsing&lt;v&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;:sings\nwalk&lt;v&gt;&lt;pres&gt;:walk\nwalk&lt;v&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;:walks\ndance&lt;v&gt;&lt;pres&gt;:dance\ndance&lt;v&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;:dances\n```\n\nКроме того можно посмотреть анализ/генерацию конкретных форм (не забудьте поставить восклицательный знак перед make в Google Colab):\n\n```{shell}\n$ make analysis FORM=\"sings\"\n\nhfst-lookup: Warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\nUsing HFST basic transducer format and performing slow lookups\n&gt; sings sing&lt;v&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;    0,000000\n```\n```{shell}\n$ make generation FORM=\"walk&lt;v&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;\"\n\nhfst-lookup: Warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\nUsing HFST basic transducer format and performing slow lookups\n&gt; walk&lt;v&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;  walks   0,000000\n```\n\nВ ходе курса мы будем разбирать разные лингвистические задачи. У каждой задачи есть номер и автоматический тест, который его проверяет. Чтобы запустить автоматическую проверку, следует ввести команду, где первое число – номер раздела, а второе число – номер задачи. Например, для того, чтобы проверить, работает ли проверка задания, попробуйте запустить следующую команду:\n\n```{shell}\n$ make test_02_01\n```\n\nЧтобы окончательно посмотреть все варианты, попробуйте изменить последнюю строчку файла task.lexd на &lt;pres&gt;&lt;3&gt;&lt;sg&gt;:S и снова перезапустить команду:\n\n```{shell}\n$ make test_02_01\n```",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Введение в `lexd`: морфология</span>"
    ]
  },
  {
    "objectID": "02_introduction_to_lexd.html#программа-lexd",
    "href": "02_introduction_to_lexd.html#программа-lexd",
    "title": "2  Введение в lexd: морфология",
    "section": "2.2 Программа lexd",
    "text": "2.2 Программа lexd\nУ программы lexd есть подробный туториал, так что данный раздел во многом опирается на него. Давайте подробнее рассмотрим lexd файл, который мы видели в прошлом разделе:\n```{lexd}\n1PATTERNS\nVerbRoot VerbInfl   \n\n2LEXICON VerbRoot\n3sing&lt;v&gt;:sing\nwalk&lt;v&gt;:walk\ndance&lt;v&gt;:dance\n\n4LEXICON VerbInfl\n5&lt;pres&gt;:\n6&lt;pres&gt;&lt;3&gt;&lt;sg&gt;:s\n```\n\n1\n\nОбязательный раздел PATTERNS, в котором каждая строка сообщает, как могут соединяться элементы из разных групп лексикона.\n\n2\n\nГруппа лексикона, которая состоит из слова LEXICON и имени, под которым данная группа появляется в разделе PATTERNS\n\n3\n\nНаполнение группы. Первым идет разбор, а потом после двоеточия языковой материал. Морфологические теги принято записывать в треугольных скобках.\n\n4\n\nВторая группа LEXICON и ее имя.\n\n5\n\nПример нулевой морфемы.\n\n6\n\nПример морфемы с несколькими морфологическими тегами.\n\n\nОтметим, что можно создавать свои именнованные подразделы PATTERN, которые потом можно использовать в разделе PATTERNS, например:\n```{lexd}\nPATTERNS\nVerbStem Tense PersonNumber\n\n1PATTERN VerbStem\nVerbRoot\nVerbRoot Causative\n\nLEXICON VerbRoot\n...\n\nLEXICON Causative\n...\n\nLEXICON Tense \n...\n\nLEXICON PersonNumber\n...\n```\n\n1\n\nИменованный раздел PATTERN, который используется потом в разделе PATTERNS.\n\n\nТаким образом, в каждом файле lexd должен быть раздел PATTERNS, содержащий в себе переменные, которые могут быть заданы либо в разделе PATTERN, либо в разделе LEXICON, либо их анонимные варианты (см. раздел Раздел 2.2.2). Также разные разделы можно переименовывать при помощи группы ALIAS (см. мануал). Комментарии можно оформлять при помощи хеша #.\n\n\n\n\n\n\nЗадание 02_02\n\n\n\nНиже представлен фрагмент ицаринской (даргинские, нахско-дагестанские) парадигмы из (Sumbatova и Mutalov 2003). Попробуйте смоделировать ее при помощи lexd. Для корректного моделирования формы sup.lat нужна морфонология, так что при моделировании используйте форму в скобках. При моделировании придется покривить душой: -б в формах ess и dir — инфикс классного показателя. Помните, что каждый морфологический тег следует обрамлять в отдельные треугольные скобки, например, ссика&lt;n&gt;&lt;ant&gt;&lt;dir&gt;:ссикасабал. Для ориентации в нашем lexd файле 26 строк.\n\n\n\nформа\nкозел\nмедведь\n\n\n\n\nabs\nкьаца\nссика\n\n\nerg\nкьацал\nссикал\n\n\ngen\nкьацала\nссикала\n\n\ncom\nкьацаццилли\nссикаццилли\n\n\nsup.lat\nкьацай (&lt; кьацайи)\nссикай (&lt; ссикайи)\n\n\nsup.ess\nкьацайиб\nссикайиб\n\n\nsup.dir\nкьацайибал\nссикайибал\n\n\nsup.el\nкьацайир\nссикайир\n\n\nsub.lat\nкьацагъу\nссикагъу\n\n\nsub.ess\nкьацагъуб\nссикагъуб\n\n\nsub.dir\nкьацагъубал\nссикагъубал\n\n\nsub.el\nкьацагъур\nссикагъур\n\n\nant.lat\nкьацаса\nссикаса\n\n\nant.ess\nкьацасаб\nссикасаб\n\n\nant.dir\nкьацасабал\nссикасабал\n\n\nant.el\nкьацасар\nссикасар\n\n\npost.lat\nкьацагьа\nссикагьа\n\n\npost.ess\nкьацагьаб\nссикагьаб\n\n\npost.dir\nкьацагьабал\nссикагьабал\n\n\npost.el\nкьацагьар\nссикагьар\n\n\nin.lat\nкьацацци\nссикацци\n\n\nin.ess\nкьацацциб\nссикацциб\n\n\nin.dir\nкьацаццибал\nссикаццибал\n\n\nin.el\nкьацаццир\nссикаццир\n\n\n\n\n\n\n2.2.1 Операторы\nКвантификация напоминает регулярные выражения:\n\n? — ноль или один раз\n* — ноль и более раз 1\n+ — один и более раз\n\n\nс операторомбез оператора\n\n\n```{lexd}\nPATTERNS\nRoot Negation?\n\nLEXICON Root\n...\n\nLEXICON Negation\n...\n```\n\n\n```{lexd}\nPATTERNS\nRoot\nRoot Negation\n\nLEXICON Root\n...\n\nLEXICON Negation\n...\n```\n\n\n\n\n| — оператор или (можно с пробелами вокруг)\n\n\nс операторомбез оператора\n\n\n```{lexd}\nPATTERNS\nRoot PastInflection|PresentInflection\n\nLEXICON Root\n...\n\nLEXICON PastInflection\n...\n\nLEXICON PresentInflection\n...\n```\n\n\n```{lexd}\nPATTERNS\nRoot PastInflection\nRoot PresentInflection\n\nLEXICON Root\n...\n\nLEXICON PastInflection\n...\n\nLEXICON PresentInflection\n...\n```\n\n\n\n\nКроме того есть операторы, названные в матералах lexd ситом, &gt; и &lt;:\n\n\nс операторомбез оператора\n\n\n```{lexd}\nPATTERNS\nVerbRoot &gt; TAM &gt; CLITICS\n\nLEXICON Root\n...\n\nLEXICON TAM\n...\n\nLEXICON CLITICS\n...\n```\n\n\n```{lexd}\nPATTERNS\nVerbRoot\nVerbRoot TAM\nVerbRoot TAM CLITICS\n\nLEXICON Root\n...\n\nLEXICON TAM\n...\n\nLEXICON CLITICS\n...\n```\n\n\n\n\n\n2.2.2 Анонимные разделы\nНекоторые фрагменты аннотации можно вставлять прямо в раздел PATTERNS. Для этого используются квадртные скобки.\n\nсокращенный вариантразвернутый вариант 1развернутый вариант 2\n\n\n```{lexd}\nPATTERNS\nNounStem [&lt;n&gt;:] NounNumber\n\nLEXICON NounStem\nsock\nninja\n\nLEXICON NounNumber\n&lt;sg&gt;:\n&lt;pl&gt;:s\n```\n\n\n```{lexd}\nPATTERNS\nNounStem NounNumber\n\nLEXICON NounStem\nsock&lt;n&gt;:sock\nninja&lt;n&gt;:ninja\n\nLEXICON NounNumber\n&lt;sg&gt;:\n&lt;pl&gt;:s\n```\n\n\n```{lexd}\nPATTERNS\nNounStem NounTag NounNumber\n\n1LEXICON NounTag\n&lt;n&gt;:\n\nLEXICON NounStem\nsock\nninja\n\nLEXICON NounNumber\n&lt;sg&gt;:\n&lt;pl&gt;:s\n```\n\n1\n\nНовый раздел LEXICON.\n\n\n\n\n\nВ мануале это трюк назван Anonymous LEXICON, видимо, потому что предполагается, что мы таким образом избегаем создания дополнительного раздела LEXICON (см. развернутый пример 2).\nПо аналогии с анонимным разделом LEXICON есть анонимный раздел PATTERN. Для этого используются круглые скобки.\n\nсокращенный вариантразвернутый вариант\n\n\n```{lexd}\nPATTERNS\n(VerbRoot Causative?) | AuxRoot Tense PersonNumber\n\nLEXICON VerbRoot\n...\n\nLEXICON Causative\n...\n\nLEXICON AuxRoot\n...\n\nLEXICON Tense \n...\n\nLEXICON PersonNumber\n...\n```\n\n\n```{lexd}\nPATTERNS\nVerbStem | AuxRoot Tense PersonNumber\n\n1PATTERN VerbStem\nVerbRoot Causative?\n\nLEXICON VerbRoot\n...\n\nLEXICON Causative\n...\n\nLEXICON AuxRoot\n...\n\nLEXICON Tense \n...\n\nLEXICON PersonNumber\n...\n```\n\n1\n\nНовый раздел PATTERN.\n\n\n\n\n\n\n\n2.2.3 Теги\nНа содержимое разделов LEXICON можно вешать теги. Это может быть полезно, например, для моделирования словоизменительных классов. Рассмотрим пример из русского языка (славянские, индоевропейские):\n```{lexd}\nPATTERNS\nNounStem[hard] Inflection[hard]\nNounStem[soft] Inflection[soft]\n\nLEXICON NounStem\nмама:мам[hard]\nпапа:пап[hard]\nняня:нян[soft]\nТаня:Тан[soft]\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:а[hard]\n&lt;nom&gt;&lt;sg&gt;:я[soft]\n&lt;gen&gt;&lt;sg&gt;:ы[hard]\n&lt;gen&gt;&lt;sg&gt;:и[soft]\n```\nТо же самое можно записать при помощи одного тега, используя операцию отмены тега:\n```{lexd}\nPATTERNS\nNounStem[hard] Inflection[hard]\nNounStem[-hard] Inflection[-hard]\n\nLEXICON NounStem\nмама:мам[hard]\nпапа:пап[hard]\nняня:нян\nбуря:бур\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:а[hard]\n&lt;nom&gt;&lt;sg&gt;:я\n&lt;gen&gt;&lt;sg&gt;:ы[hard]\n&lt;gen&gt;&lt;sg&gt;:и\n```\nОднако в русском языке можно найти аффиксы, которые присоединяются к обоим типам основ, в таком случае, придется усложнить наше описание:\n```{lexd}\nPATTERNS\nNounStem[hard] Inflection[hard]\nNounStem[soft] Inflection[soft]\nNounStem Inflection[-hard,-soft]\n\nLEXICON NounStem\nмама:мам[hard]\nпапа:пап[hard]\nняня:нян[soft]\nТаня:Тан[soft]\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:а[hard]\n&lt;nom&gt;&lt;sg&gt;:я[soft]\n&lt;gen&gt;&lt;sg&gt;:ы[hard]\n&lt;gen&gt;&lt;sg&gt;:и[soft]\n&lt;pos&gt;:ин\n```\nАвторы lexd добавили возможность взаимодействия тегов, чтобы не надо было писать одно и то же.\n\n(A B)[x]  = (A[x] B) | (A B[x])\n\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\n(A B)[x]\n\nLEXICON A\naaa[x]\nbbb\n\nLEXICON B\nAAA[x]\nBBB\n```\n\n\naaaAAA\naaaBBB\nbbbAAA\n\n\n\n\n(A B)[-x] = A[-x] B[-x]\n\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\n(A B)[-x]\n\nLEXICON A\naaa[x]\nbbb\n\nLEXICON B\nAAA[x]\nBBB\n```\n\n\nbbbBBB\n\n\n\n\nA[|[x,y]] = A[x] | A[y]\n\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\nA[|[x,y]]\n\nLEXICON A\naaa[x]\nbbb[y]\nccc\n```\n\n\naaa\nbbb\n\n\n\n\nA[^[x,y]] = A[x,-y] | A[-x,y]\n\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\nA[^[x,y]]\n\nLEXICON A\naaa[x]\nbbb[y]\nccc[z]\nddd[x,y]\neee[x,z]\nfff[y,z]\nggg\n```\n\n\naaa\neee\nbbb\nfff \n\n\n\n^ — очень полезный оператор, который позволяет смоделировать согласование по признакам\n(A B)[^[x,y]] = (A[x,-y] B[x,-y]) | (A[-x,y] B[-x, y]):\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\n(A B)[^[x,y]]\n\nLEXICON A\naaa[x]\nbbb[y]\nccc\n\nLEXICON B\nAAA[x]\nBBB[y]\nCCC\n```\n\n\naaaAAA\naaaCCC\ncccAAA\ncccBBB\nbbbCCC\nbbbBBB\n\n\n\nЭто позволяет смоделировать наш русский пример одной строчкой:\n\nс операторомстарый вариант\n\n\n```{lexd}\nPATTERNS\n(NounStem Inflection)[^[hard,soft]]\n\nLEXICON NounStem\nмама:мам[hard]\nпапа:пап[hard]\nняня:нян[soft]\nТаня:Тан[soft]\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:а[hard]\n&lt;nom&gt;&lt;sg&gt;:я[soft]\n&lt;gen&gt;&lt;sg&gt;:ы[hard]\n&lt;gen&gt;&lt;sg&gt;:и[soft]\n&lt;pos&gt;:ин\n```\n\n\n```{lexd}\nPATTERNS\nNounStem[hard] Inflection[hard]\nNounStem[soft] Inflection[soft]\nNounStem Inflection[-hard,-soft]\n\nLEXICON NounStem\nмама:мам[hard]\nпапа:пап[hard]\nняня:нян[soft]\nТаня:Тан[soft]\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:а[hard]\n&lt;nom&gt;&lt;sg&gt;:я[soft]\n&lt;gen&gt;&lt;sg&gt;:ы[hard]\n&lt;gen&gt;&lt;sg&gt;:и[soft]\n&lt;pos&gt;:ин\n```\n\n\n\n\n\n\n\n\n\nЗадание 02_03\n\n\n\nНиже представлен фрагмент финской (фино-угорские, уральские) парадигмы (Karlsson 2013), как видно, здесь слова двух словоизменительных типов. Попробуйте смоделировать представленную парадигму, используя теги.\n\n\n\nglosses\nзал\nобщежитие\nдверь\nзима\n\n\n\n\nnom.sg\nsali\nhostelli\novi\ntalvi\n\n\nacc.sg\nsali\nhostelli\novi\ntalvi\n\n\ngen.sg\nsalin\nhostellin\noven\ntalven\n\n\nprt.sg\nsalia\nhostellia\novea\ntalvea\n\n\nin.ess.sg\nsalissa\nhostellissa\novessa\ntalvessa\n\n\nin.abl.sg\nsalista\nhostellista\novesta\ntalvesta\n\n\nat.ess.sg\nsalilla\nhostellilla\novella\ntalvella\n\n\nat.abl.sg\nsalilta\nhostellilta\novelta\ntalvelta\n\n\nat.all.sg\nsalille\nhostellille\novelle\ntalvelle\n\n\nfrml.sg\nsalina\nhostellina\novena\ntalvena\n\n\ntrans.sg\nsaliksi\nhostelliksi\noveksi\ntalveksi\n\n\npriv.sg\nsalitta\nhostellitta\novetta\ntalvetta\n\n\n\n\n\n\n\n2.2.4 Моделирование разрывных морфем: инфиксы, редупликация, семитские корни\nВ разеделе PATTERNS можно перечислять разные стороны единиц (или входное и выходное значение), записанных в LEXICON2. Это позволяет:\n\nопускать либо глоссы, либо морфемы (полезно для моделирования редупликации);\nиметь разный порядок глосс и морфем (но зачем?).\n\nВот пример моделирования дистрибутивных числительных (т. е. числительных со значением ‘по Х’) в зиловском андийском (андийские, нахско-дагестанские):\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\nNumerals NumeralMarker\nNumeralReduplication :Numerals Numerals NumeralMarker NumeralDistributiveMarker\n\nLEXICON Numerals\nчIе               # числительное 2\nлъоб              # числительное 3\nойлIи             # числительное 6\n\nLEXICON NumeralMarker\n&lt;num&gt;:гу\n\nLEXICON NumeralDistributiveMarker\n&lt;distr&gt;:\n\nLEXICON NumeralReduplication\n&lt;rdp&gt;:\n```\n\n\nчIе&lt;num&gt;:чIегу\nлъоб&lt;num&gt;:лъобгу\nойлIи&lt;num&gt;:ойлIигу\n&lt;rdp&gt;чIе&lt;num&gt;&lt;distr&gt;:чIечIегу\n&lt;rdp&gt;лъоб&lt;num&gt;&lt;distr&gt;:лъоблъобгу\n&lt;rdp&gt;ойлIи&lt;num&gt;&lt;distr&gt;:ойлIиойлIигу\n\n\n\nКроме того для моделирования разрывных морфем, вводится номер в круглых скобках, а элементы морфемы перечисляются через пробел. Вот пример, из иврита (симитские, афразийские):\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\nC(1) V(1) C(2) :V(2) C(3) V(2):\n\nLEXICON C(3)\nsh m r          # соблюдать, защищать\ny sh v          # садиться\n\nLEXICON V(2)\n:a &lt;v&gt;&lt;p3&gt;&lt;sg&gt;:a\n:o &lt;v&gt;&lt;pprs&gt;:e\n```\n\n\nshmr&lt;v&gt;&lt;p3&gt;&lt;sg&gt;:shamar\nshmr&lt;v&gt;&lt;pprs&gt;:shomer\nyshb&lt;v&gt;&lt;p3&gt;&lt;sg&gt;:yashab\nyshb&lt;v&gt;&lt;pprs&gt;:yosheb\n\n\n\n\n\n\n\n\n\nЗадание 02_04\n\n\n\nНиже даны количественные, кратные (со значение ‘Х раз’) и дистрибутивные (со значение ‘по Х’) числительные адыгейского языка (абхазо-адыгские) (Рогава и Керашева 1966: 79, 81). Смоделируйте перечисленные формы:\n\n\n\n\n\n\n\n\n\n\nзначение\nлемма\nколичественные &lt;card&gt;\nкратные  &lt;adv&gt;\nдистрибутивные  &lt;distr&gt;\n\n\n\n\n1\nзы\nзы\nзэ\nзырыз\n\n\n3\nщы\nщы\nщэ\nщырыщ\n\n\n4\nплIы\nплIы\nплIэ\nплIырыплI\n\n\n5\nтфы\nтфы\nтфэ\nтфырытф\n\n\n6\nхы\nхы\nхэ\nхырых\n\n\n10\nпшIы\nпшIы\nпшIэ\nпшIырыпшI\n\n\n\n\n\n\n\n2.2.5 Регулярные выражения\nВ разделе LEXICON допускаются регулярные выражения, для этого их нужно обромлять косыми чертами /:\n\nгруппировка при помощи скобок ()\nквантификация при помощи ?, *, и +. Объект квантификации должен быть обрамлен круглыми скобками.\nлогическое ‘или’ |\nгруппы символов при помощи квадратных скобок []\nпромежутки символов [a-z]\n\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\nSomeLexicon\n\nLEXICON SomeLexicon\n/x(y|zz)?[n-p]/\n```\n\n\nxyn\nxyo\nxyp\nxzzn\nxzzo\nxzzp\nxn\nxo\nxp\n\n\n\nЭто позволяет добавлять разбор неизвестных единиц в lexd. Важно отметить, что добавление некоторых типов регулярных выражение делает циклический трансдьюсер, поэтому результат такого трансдьюссера можно посмотреть только при помощи команд make analysis FORM=\"...\" или make generation FORM=\"...\".\n\nlexdрезультат\n\n\n```{lexd}\nPATTERNS\nStem Affix\n\nLEXICON Stem\nстол\nдом\n/([а-я])*/\n\nLEXICON Affix\n&lt;nom&gt;&lt;sg&gt;:\n&lt;gen&gt;&lt;sg&gt;:а\n&lt;acc&gt;&lt;sg&gt;:\n&lt;dat&gt;&lt;sg&gt;:у\n&lt;ins&gt;&lt;sg&gt;:ом\n&lt;loc&gt;&lt;sg&gt;:е\n```\n\n\n```{shell}\n$ make analysis FORM=\"комом\"\n\nhfst-lookup: Warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\nUsing HFST basic transducer format and performing slow lookups\n&gt; комом ком&lt;ins&gt;&lt;sg&gt;    0,000000\nкомом   комом&lt;acc&gt;&lt;sg&gt;  0,000000\nкомом   комом&lt;nom&gt;&lt;sg&gt;  0,000000\n```\n\n\n\n\n\n\n\nKarlsson, F. 2013. Finnish: An essential grammar. Routledge.\n\n\nLindén, K., E. Axelson, S. Hardwick, T. A. Pirinen, и M. Silfverberg. 2011. «Hfst—framework for compiling and applying morphologies». В Systems and Frameworks for Computational Morphology: Second International Workshop, SFCM 2011, Zurich, Switzerland, August 26, 2011. Proceedings 2, 67–85. Springer.\n\n\nOrtiz Rojas, S., M. L. Forcada, и G. Ramı́rez Sánchez. 2005. «Construcción y minimización eficiente de transductores de letras a partir de diccionarios con paradigmas». Procesamiento del lenguaje natural 35: 51–57.\n\n\nSumbatova, N. R., и R. O. Mutalov. 2003. A grammar of Itsari Dargwa. Muenchen: Lincom Europa.\n\n\nSwanson, D., и N. Howell. 2021. «Lexd: A finitestate lexicon compiler for non-suffixational morphologies». В Multilingual Facilitation, 133–46.\n\n\nРогава, Г. В., и З. И. Керашева. 1966. Грамматика адыгейского языка. Майкоп, Краснодар: Краснодарское книж. издательство.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Введение в `lexd`: морфология</span>"
    ]
  },
  {
    "objectID": "02_introduction_to_lexd.html#footnotes",
    "href": "02_introduction_to_lexd.html#footnotes",
    "title": "2  Введение в lexd: морфология",
    "section": "",
    "text": "Мы какое-то время думали, зачем это может быть нужно и придумали только странные сценарии типа пра-пра-пра-пра-бабушка. Но вообще это порождает циклы, от которых одни проблемы.↩︎\nК сожалению, нельзя делать аналогичное для единиц из разделов PATTERN.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Введение в `lexd`: морфология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html",
    "href": "03_phonological_rules.html",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "",
    "text": "3.1 Фонологическое введение\nПреобладающая фонологическая теория в XX веке — генеративная фонология (Chomsky и Halle 1968). Согласно этой теории существует два представления: глубинное (underlying/phonological representation) и поверхностное (surface form, phonetic representation). Фонология в этой теории сводится к набору линейно упорядоченных правил, которые применяются циклически, преобразуя результат работы синтаксической деревации в фонетические цепочки.\nИз-за того, что правила в этой теории строго упорядочены возникают случаи, когда правила взаимодействуют друг с другом. Классификация таких случаев приводится в работе (Kiparsky 1982 (1968)):\nВот комиксы, которые по нашей задумке должны дополнительно иллюстрировать разницу между разными порядками.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html#фонологическое-введение",
    "href": "03_phonological_rules.html#фонологическое-введение",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "",
    "text": "глубинное представление &gt; фонологическое правило 1 &gt; фонологическое правило 2 &gt; … &gt; поверхностное представление.\n\n\n\nпитающий порядок (feeding). Так называют порядок, при котором применение одного правила увеличивает количество контекстов применение другого правила, так что другое правило срабатывает. 1\nблокирующий порядок (bleeding). Так называют порядок, при котором применение одного правила уменьшает количество контекстов применения другого правила, так что другое правило не срабатывает. 2\nпротивопитающий порядок (counterfeeding). Так называют порядок, при котором применение одного правила увеличивает количество контекстов применение другого правила, однако другое правило не срабатывает.\nпротивоблокирующий порядок (counterbleeding). Так называют порядок, при котором применение одного правила уменьшает количество контекстов применения другого правила, однако другое правило все равно срабатывает.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html#двухуровневая-фонологияморфология",
    "href": "03_phonological_rules.html#двухуровневая-фонологияморфология",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "3.2 Двухуровневая фонология/морфология",
    "text": "3.2 Двухуровневая фонология/морфология\nДвухуровневая фонология/морфология (two level morphology) была разработана в диссертации (Koskenniemi 1983). Стоит отметить, что мы используем данный формализм для моделирования (мор)фонологических правил, однако данный формализм называют двухуровневой морфологией (в том числе и сам автор). Вообще, еще в 1972 вышла диссертация (Johnson 1972), в которой автор указывал на некоторые недостатки последовательности фонологических правил, которые были приняты в генеративной фонологии, а также доказывал, что любую последовательность правил можно моделировать при помощи трансдьюсера, однако эта работа осталась незамеченной.\nВ рамках двухуровневой фонологии/морфологии:\n\nправила — посимвольные ограничения на поверхностное представление, которые применяются параллельно.\nправила могут оперировать единицами глубинного (другое название — лексическое) представления, поверхностного представления или одновременно обоих.\n\nНапример, получить из глубинной формы spy&gt;s поверхностную форму spies можно двумя правилами (нотацию мы подробнее обсудим позже):\n\ny:i &lt;=&gt; _ 0:e\n0:e &lt;=&gt; y: _ %&gt;:0\n\nПервое правило обращается одновременно к глубинному (0:) и поверхностному (:e) представлениям. Второе правило обращается только к глубинному представлению (y:) и поверхностному (%&gt;:0) представлениям.\nИспользование ограничений, вместо правил, чуть позже возникла в фонологии в виде Теории оптимальности (OT, (Prince и Smolensky 1994)), однако в рамках OT предпалагаются, что ограничения носят универсальный характер и есть во всех языках, в то время, как ограничения двухуровневой фонологии/морфологии — имеют частный внутриязыковой характер.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html#программа-twol",
    "href": "03_phonological_rules.html#программа-twol",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "3.3 Программа twol",
    "text": "3.3 Программа twol\nВ данном разделе мы будем обсуждать синтаксис twol. Данный раздел основан на (Beesley и Karttunen 2003). Кроме того Элен Картина обратила мое внимание на пакет twol для Python, разработанный Киммо Коскенниэми, автором twol.\n\n3.3.1 Техническое введение\nМы будем использовать программу hfst-twolc. Чтобы избежать сложностей на начальных этапах курса, мы решили вначале познакомиться с синтаксисом twol и попробовать описывать разные языковые явления, не затрудняя всех установкой и запуском нужных программ у себя на компьютере.\n\nДля начала работы следует, как и раньше, скачать Makefile:\n\n```{shell}\n$ curl -s https://raw.githubusercontent.com/agricolamz/2025_morphological_transducers/refs/heads/main/task_tests/Makefile -o Makefile; make\n```\n\nдальше, как и раньше, следует создать в колабе или у себя на компьютере (если у вас Linux), файл с названием task.lexd. В Google Colab для этого достаточно вставить первой строкой кодового блока %%writefile task.lexd. Вот пример такого файла:\n\n```{lexd}\nPATTERNS\nNoun (Suffix[-adj] | (Suffix[adj] Inflection))?\n\nLEXICON Noun\nночь\nпечь\n\nLEXICON Suffix\n&lt;dim&gt;:ка\n&lt;adj&gt;:н[adj]\n\nLEXICON Inflection\n&lt;m&gt;&lt;sg&gt;&lt;nom&gt;:ой\n```\n\nнововведением является возможность создания файла с названием task.twol, в котором будет содержаться код для обработки (мор)фонологии. Не забудьте вставить %%writefile task.twol в Google Colab. Вот пример такого файла:\n\n```{twol}\nAlphabet\n  а е й к н о п ч ь ь:0;\n\nRules\n\n\"чк чн пишется без ь\"\n! например, ночьной -&gt; ночной или печька -&gt; печка\n\nь:0 &lt;=&gt; _ к;\n        _ н;\n```\n\nПосле того, как вы установили нужные программы и создали файлы, как и раньше, можно посмотреть формы и разборы, которые генерируются трансдьюсером (не забудьте поставить восклицательный знак перед make в Google Colab):\n\n```{shell}\n$ make forms\n\nночь&lt;dim&gt;:ночка\nночь&lt;adj&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;:ночной\nночь\nпечь&lt;dim&gt;:печка\nпечь&lt;adj&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;:печной\nпечь\n```\n\nКроме того можно посмотреть анализ/генерацию конкретных форм (не забудьте поставить восклицательный знак перед make в Google Colab):\n\n```{shell}\n$ make analysis FORM=\"печка\"\n\nhfst-lookup: Warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\nUsing HFST basic transducer format and performing slow lookups\n&gt; печка печь&lt;dim&gt;   0,000000\n```\n```{shell}\n$ make generation FORM=\"ночь&lt;adj&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;\"\n\nhfst-lookup: Warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\nUsing HFST basic transducer format and performing slow lookups\n&gt; ночь&lt;adj&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt; ночной  0,000000\n```\n\nКак и раньше, получившийся трансдьюсер можно протестировать:\n\n```{shell}\n$ make test_03_01\n```\n\nК сожалению, сейчас, если была получена ошибка из программы twol следует удалить лишние созданные файлы перед тем как приступить к исправлению:\n\n```{shell}\n$ make clean\n```\n\n\n3.3.2 Структура twol файла\nКаждый twol файл состоит из нескольких блоков, которые удобно обсуждать на приведенном выше примере:\n```{twol}\n1Alphabet\n2  а е й к н о п ч ь ь:0;\n\n3Rules\n\n4\"чк чн пишется без ь\"\n5! например, ночьной -&gt; ночной или печька -&gt; печка\n\n6ь:0 &lt;=&gt; _ к;\n7        _ н;\n```\n\n1\n\nРаздел, которые перечисляет все используемые символы.\n\n2\n\nДекларацией конца раздела является точка с запятой, поэтому иногда удобно писать элементы в несколько строчек, особенно если есть некотрые логические блоки. Из примера видно сокращение: одним символом можно записывать идентичные пары входного и выходного символов (т. е. й:й можно записывать как й).\n\n3\n\nРаздел с правилами.\n\n4\n\nНазвание правила (паразительно, но это обязательный элемент 3).\n\n5\n\nВ любом месте файла можно написать комментарий. Начало комментария обозначается восклицательным знаком.\n\n6\n\nСамо правило. Оно обычно имеет следующие элементы: какая-то пара входного/выходного символа (ь:0), дальше оператор (&lt;=&gt;), дальше контекст (_ к), все это заканчивается точкой с запятой.\n\n7\n\nНесколько контекстов для одного правила можно записывать вместе. На всякий случай — отбивка не важна, просто сделал для удобочитаемости.\n\n\n\n\n3.3.3 Раздел алфавита\nХорошо бы, чтобы раздел алфавита содержал все пары символов (по-английски, symbol pairs или feasible pairs) глубинного и поверхностного представлений, которые представлены в вашем материале. Важно отметить, что twol достраивает пары символов из правил, так что программа будет работать и с неполным алфавитом .twol. Для нашего примера достаточно следующего файла:\n```{twol}\nAlphabet\n  ь;\n\nRules\n\n\"чк чн пишется без ь\"\n\nь:0 &lt;=&gt; _ к;\n        _ н;\n```\nТак как под капотом происходит композиция трансдьюсеров (см. Раздел 1.4.2), то символы, которые не участвуют в правилах twol, не будут затронуты. И, единственное, что twol не может восстановить, что у нас есть две сущности: ь:0 и ь:ь.\nОднако все это из разряда вредных советов. Если вы моделируете язык или даже его фрагмент, лучше перечислить все символы (и их прописные варианты). Это позволит избежать проблем при анализе некачественных входных данных.\n\n\n3.3.4 Архифонемы\nИногда (мор)фонологические проблемы можно решать, не постулируя некоторую конкретную сегментную глубинную форму, а используя, так называемые архифонемы4. Эти единицы записываются в lexd в фигурных скобках, например {А}. Существует конвенция, что если архифонема позже только удаляется, то ее пишут строчными буквами, например, {s}, а если архифонема представляет собой набор поверхностных форм, то ее пишут заглавными буквами, например, {А}. Важно отметить, что в файле .twol фигурные скобки нужно экранировать при помощи знака процента %. Для примера давайте перемоделируем пример из прошлого раздела:\n\nlexdtwolдо применения twolпосле применения twolстарый файл lexd\n\n\n```{lexd}\nPATTERNS\nNounStem Inflection\n\nLEXICON NounStem\nмама:мам\nпапа:пап\nняня:нян{j}\nТаня:Тан{j}\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:{А}\n&lt;gen&gt;&lt;sg&gt;:{Ы}\n&lt;pos&gt;:ин\n```\n\n\n```{twol}\nAlphabet\n  а и м н п я Т\n  %{А%}:а %{А%}:я %{Ы%}:ы %{Ы%}:и %{j%}:0;\n\nRules\n\n\"удаляем маркер мягкой основы\" \n\n%{j%}:0 &lt;=&gt; _ ;\n\n\"гласные после мягкой основы в именительном\" \n\n%{А%}:я &lt;=&gt; %{j%}:0 _ ;\n\n\"гласные после мягкой основы в родительном\" \n\n%{Ы%}:и &lt;=&gt; %{j%}:0 _ ;\n```\n\n\nмама&lt;nom&gt;&lt;sg&gt;:мам{А}\nмама&lt;gen&gt;&lt;sg&gt;:мам{Ы}\nмама&lt;pos&gt;:мамин\nпапа&lt;nom&gt;&lt;sg&gt;:пап{А}\nпапа&lt;gen&gt;&lt;sg&gt;:пап{Ы}\nпапа&lt;pos&gt;:папин\nняня&lt;nom&gt;&lt;sg&gt;:нян{j}{А}\nняня&lt;gen&gt;&lt;sg&gt;:нян{j}{Ы}\nняня&lt;pos&gt;:нян{j}ин\nТаня&lt;nom&gt;&lt;sg&gt;:Тан{j}{А}\nТаня&lt;gen&gt;&lt;sg&gt;:Тан{j}{Ы}\nТаня&lt;pos&gt;:Тан{j}ин  \n\n\nмама&lt;nom&gt;&lt;sg&gt;:мама\nмама&lt;gen&gt;&lt;sg&gt;:мамы\nмама&lt;pos&gt;:мамин\nпапа&lt;nom&gt;&lt;sg&gt;:папа\nпапа&lt;gen&gt;&lt;sg&gt;:папы\nпапа&lt;pos&gt;:папин \nняня&lt;nom&gt;&lt;sg&gt;:няня\nняня&lt;gen&gt;&lt;sg&gt;:няни\nняня&lt;pos&gt;:нянин\nТаня&lt;nom&gt;&lt;sg&gt;:Таня\nТаня&lt;gen&gt;&lt;sg&gt;:Тани\nТаня&lt;pos&gt;:Танин\n\n\n```{lexd}\nPATTERNS\nNounStem[hard] Inflection[hard]\nNounStem[soft] Inflection[soft]\nNounStem Inflection[-hard,-soft]\n\nLEXICON NounStem\nмама:мам[hard]\nпапа:пап[hard]\nняня:нян[soft]\nТаня:Тан[soft]\n\nLEXICON Inflection\n&lt;nom&gt;&lt;sg&gt;:а[hard]\n&lt;nom&gt;&lt;sg&gt;:я[soft]\n&lt;gen&gt;&lt;sg&gt;:ы[hard]\n&lt;gen&gt;&lt;sg&gt;:и[soft]\n&lt;pos&gt;:ин\n```\n\n\n\nСледует обратить внимание, на то, что мы не писали правил для пар {А}:а и {Ы}:ы. twol сам использовал указанные нами переходы во всех контекстах, не специализированных правилом перехода после мягких основ. Это поведение напрямую зависит от оператора, используемого в правиле (см. раздел Раздел 3.3.8).\nАрхифонемы позволяют моделировать морфонологические правила, так как мы всегда можем вставить единицу {some_name}:0, которая показывает на важную морфонологическую границу, рядом с которой что-то происходит.\n\n\n\n\n\n\nЗадание 03_02\n\n\n\nВ работе (Иткин 2007: 118) описано чередование н~н’ в русском языке. Попробуйте заполнить раздел Rules в файле .twol, чтобы получился трансдьюсер, моделирующий следующие формы:\n\n\n\n&lt;nom&gt;&lt;sg&gt;\n&lt;dat&gt;&lt;sg&gt;\n&lt;ins&gt;&lt;pl&gt;\n&lt;gen&gt;&lt;pl&gt;\n\n\n\n\nбашня\nбашней\nбашнями\nбашен\n\n\nпесня\nпесней\nпеснями\nпесен\n\n\nбойня\nбойней\nбойнями\nбоен\n\n\nдеревня\nдеревней\nдеревнями\nдеревень\n\n\nкухня\nкухней\nкухнями\nкухонь\n\n\nТаня\nТаней\nТанями\nТань\n\n\n\n\nlexdtwol\n\n\n```{lexd}\nPATTERNS\n(NounRoot NounInfl)[^[hard,soft]]\n\nLEXICON NounRoot\nбашня&lt;n&gt;:баш{Е}н[hard]\nпесня&lt;n&gt;:пес{Е}н[hard]\nбойня&lt;n&gt;:бой{Е}н[hard]\nдеревня&lt;n&gt;:дерев{Е}н[soft]\nкухня&lt;n&gt;:кух{О}н[soft]\nТаня&lt;n&gt;:Тан[soft]\n\nLEXICON NounInfl\n&lt;nom&gt;&lt;sg&gt;:я\n&lt;dat&gt;&lt;sg&gt;:ей\n&lt;dat&gt;&lt;pl&gt;:ями\n&lt;gen&gt;&lt;pl&gt;:{GEN.PL}[hard]\n&lt;gen&gt;&lt;pl&gt;:{GEN.PL}ь[soft]\n```\n\n\n```{twol}\nAlphabet\n    б ш н п с й д р в к х Т м ь\n    а я е у и о\n    %{Е%}:0 %{О%}:0 %{GEN.PL%}:0 \n    %{Е%}:е %{О%}:о\n    й:0\n;\n\nRules\n\n```\n\n\n\n\n\n\n\n3.3.5 Обращение к разным представлениям\nЕдинцы, которыми манипулирует twol — пары глубинного и поверхносного представления. Поэтому в правилах могут появлятся\n\nполностью определенные единицы, например, а:ы или ь:0\nединицы, определенные только на одном из представлений\n\nглубинном, например, ы:\nповерхностном, например, :я\n\nplaceholder со значением любой знак: : (еще можно ?)\n\n\n\n3.3.6 Разделы Sets и Definitions\nРаздел Sets — опциональный раздел .twol файла, в котором можно создать группы символов, к которым потом можно обращаться в правилах по имени. Рассмотрим пример моделирования устранение зияния гласных в адыгейском языке (Аркадьев и др. 2009: 27–28):\n\n\n\n\n&lt;abs&gt;\n‘это не X’  &lt;neg&gt;\n‘это X?’  \n\n\n\n\nженщина\nшъуз\nшъузэп\nшъуза\n\n\nмужчина\nлIы\nлIэп\nлIа\n\n\nдом\nунэ\nунэп\nуна\n\n\n\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot Infl\n\nLEXICON Root\nшъуз\nлIы\nунэ\n\nLEXICON Infl\n&lt;abs&gt;:\n&lt;neg&gt;:эп\n&lt;q&gt;:а\n```\n\n\n```{twol}\nAlphabet\n    I а з л н п у ш ъ ы э\n    а:0 ы:0 э:0;\n    \nSets\n    Vowels = а ы э;\n\nRules\n\n\"устранение зияния гласных\"\nVowels:0 &lt;=&gt; _ Vowels;\n```\n\n\nлIы&lt;q&gt;:лIа\nлIы&lt;neg&gt;:лIэп\nлIы&lt;abs&gt;:лIы\nунэ&lt;q&gt;:уна\nунэ&lt;neg&gt;:унэп\nунэ&lt;abs&gt;:унэ\nшъуз&lt;abs&gt;:шъуз\nшъуз&lt;q&gt;:шъуза\nшъуз&lt;neg&gt;:шъузэп\n\n\n\nОбратим внимание, что Vowels:0 в рамках нашей задачи можно было бы записать экономичнее :0 (см. ниже раздел Раздел 3.3.5). Однако, такое правило при моделировании большего фрагмента грамматики скорее всего может привести к непредвиденным эффектам. Тем более, что такая запись плохо читаема вне контекста.\nОпределение множеств может содержать имена множеств, определенных ранее. Все перечисленные в множествах единицы должны быть определены в разделе Alphabet.\nСледует отметить, что переменная Vowels в нашем .twol файле раскрылась всеми возможными способами: а – а, а – ы, а – э, ы – ы, ы – э, э – э.\nРаздел Definitions — опциональный раздел .twol файла, в котором можно давать некоторым левым или правым контекстам имена, к которым потом можно обращаться в правилах. Это осмысленно, если один и тот же контекст встречается в разных правилах, пример из (Beesley и Karttunen 2003: 29)\n```{twol}\n...\nDefinitions\n\n  XContext = [ p | t | k | g:k ] ;\n  YContext = [ m | n | n g ] ;\n  \n...\n```\nКроме того, внутри правил можно создавать свои переменные. Так адыгейский трансдьюсер для устранения зияния гласных можно переписать, опеределяя переменную прямо в правиле, а не в разделе Sets:\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot Infl\n\nLEXICON Root\nшъуз\nлIы\nунэ\n\nLEXICON Infl\n&lt;abs&gt;:\n&lt;neg&gt;:эп\n&lt;q&gt;:а\n```\n\n\n```{twol}\nAlphabet\n    I а з л н п у ш ъ ы э\n    а:0 ы:0 э:0;\n\nRules\n\n\"устранение зияния гласных\"\nVowels:0 &lt;=&gt; _ [а | ы | э];\n    where Vowels in (а ы э);\n```\n\n\nлIы&lt;q&gt;:лIа\nлIы&lt;neg&gt;:лIэп\nлIы&lt;abs&gt;:лIы\nунэ&lt;q&gt;:уна\nунэ&lt;neg&gt;:унэп\nунэ&lt;abs&gt;:унэ\nшъуз&lt;abs&gt;:шъуз\nшъуз&lt;q&gt;:шъуза\nшъуз&lt;neg&gt;:шъузэп\n\n\n\nКажется, что правило можно было бы еще упростить и использовать переменную дважды:\nVowels:0 &lt;=&gt; _ Vowels;\n    where Vowels in (а ы э);\nК сожалению, это работает неправильно:\nлIы&lt;abs&gt;:лIы\nлIы&lt;q&gt;:лIыа\nлIы&lt;neg&gt;:лIыэп\nунэ&lt;neg&gt;:унэп\nунэ&lt;abs&gt;:унэ\nунэ&lt;q&gt;:унэа\nшъуз&lt;abs&gt;:шъуз\nшъуз&lt;q&gt;:шъуза\nшъуз&lt;neg&gt;:шъузэп \nДело в том, что программа расписывает такое правило следующим образом:\nа:0 &lt;=&gt; _ а;\nы:0 &lt;=&gt; _ ы;\nэ:0 &lt;=&gt; _ э;\nА для корректной работы, нужно следующее расписывание:\nа:0 &lt;=&gt; _ [а ы э];\nы:0 &lt;=&gt; _ [а ы э];\nэ:0 &lt;=&gt; _ [а ы э];\nИнтересно, почему это работало в случае, если определить переменную в разделе Sets.\nПеременных может быть несколько, и после их определения значения у созданных переменных можно соединить, используя аргумент matched. Рассмотрим это на примере палатализации в польском (индоевропейские, славянские):\n\n\n\n\nпризнак\nнога\nрука\n\n\n\n\n&lt;nom&gt;&lt;sg&gt;\ncecha\nnoga\nręka\n\n\n&lt;acc&gt;&lt;sg&gt;\ncechę\nnogę\nrękę\n\n\n&lt;dat&gt;&lt;sg&gt;\ncesze\nnodze\nręce\n\n\n\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot Infl\n\nLEXICON Root\ncecha&lt;n&gt;:cech\nnoga&lt;n&gt;:nog\nręka&lt;n&gt;:ręk\n\nLEXICON Infl\n&lt;nom&gt;&lt;sg&gt;:a\n&lt;acc&gt;&lt;sg&gt;:ę\n&lt;dat&gt;&lt;sg&gt;:{dat.sg}e\n```\n\n\n```{twol}\nAlphabet\n    a c h e n o g r ę k\n    k:c g:dz h:sz c:0\n    %{dat.sg%}:0;\n\nRules\n\n\"палатализация\"\nC:Cpal &lt;=&gt; _ %{dat.sg%}:0;\n    where C in (k g h)\n          Cpal in (c dz sz)\n          matched ;\n\n\"починка диграфа ch -&gt; sz\"\nc:0 &lt;=&gt; _ h:sz;\n\n\"гиперфонема для дательного\"\n%{dat.sg%}:0 &lt;=&gt; _;\n```\n\n\ncecha&lt;n&gt;&lt;dat&gt;&lt;sg&gt;:cesze\ncecha&lt;n&gt;&lt;nom&gt;&lt;sg&gt;:cecha\ncecha&lt;n&gt;&lt;acc&gt;&lt;sg&gt;:cechę\nnoga&lt;n&gt;&lt;nom&gt;&lt;sg&gt;:noga\nnoga&lt;n&gt;&lt;acc&gt;&lt;sg&gt;:nogę\nnoga&lt;n&gt;&lt;dat&gt;&lt;sg&gt;:nodze\nręka&lt;n&gt;&lt;nom&gt;&lt;sg&gt;:ręka\nręka&lt;n&gt;&lt;acc&gt;&lt;sg&gt;:rękę\nręka&lt;n&gt;&lt;dat&gt;&lt;sg&gt;:ręce\n\n\n\nВ файле .twol в правиле палатализация были созданы две переменные C и Cpal, которые были определены ниже. Также в этом .twol файле есть пример соответствия одному входному символу многосимвольный выход (g:dz). К сожалению, нельзя определять многосимвольные входные символы кроме как через гиперфонемы. matched в правиле означает, не свободное определение переменных, а определенные отношения, если определено несколько переменных: первый элемент одной переменной соотносится с первым элементом второй переменной и т. д. Если matched убрать, то программа будет генерировать все возможные комбинации.\n\n\n3.3.7 Операторы и другое\n\n.#. — означает границу слова (как левую так, и правую)\nОператоры квантификации\n\nОператор ? — ноль или один раз\nОператор * — ноль и более раз\nОператор + — один и более раз\nОператор ^n — n раз\nОператор ^n,m — от n до m раз\n\n\nОператоры квантификации важны, так как позволяют задавать сложные контексты для моделирования дистантных отношений.\n\nОператор \\ работает как логическое не, например \\Vowels задает контекст для единц, не входящих в группу Vowels.\n\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot\n\nLEXICON Root\naa \nba \nla \nma \nxa \nya \nza\n```\n\n\n```{twol}\nAlphabet\n    a b l m x y z a:b;\n\nSets\n    X = x y z;\n\nRules\n\n\"change\"\na:b &lt;=&gt; \\X _;\n```\n\n\naa:bb\nba:bb\nxa      # есть в X\nya      # есть в X\nza      # есть в X\nla:lb\nma:mb\n\n\n\n\nОператор | имеет семантику ‘или’, что в данном случае будет работать как объединение множеств\n\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot\n\nLEXICON Root\naa \nba \nla \nma \nxa \nya \nza\n```\n\n\n```{twol}\nAlphabet\n    a b l m x y z a:b;\n\nSets\n    X = x y z;\n    Y =   y z l m;\n\nRules\n\n\"change\"\na:b &lt;=&gt; X | Y _;\n```\n\n\naa\nba\nxa:xb   # есть в X\nya:yb   # есть и в X, и Y\nza:zb   # есть и в X, и Y\nla:lb   # есть в Y\nma:mb   # есть в Y\n\n\n\nТак в одном из примеров выше для переходов после мягких основ существует одинаковый контекст, так что можно использовать объединение при помощи оператора | (квадратные скобки добавлены для удобочитаемости, работает и без них):\n\nс операторомбез оператора как выше\n\n\n```{twol}\nAlphabet\n  а и м н п я Т\n  %{А%}:а %{А%}:я %{Ы%}:ы %{Ы%}:и %{j%}:0;\n\nRules\n\n\"удаляем маркер мягкой основы\" \n\n%{j%}:0 &lt;=&gt; _ ;\n\n\"гласные после мягкой основы\" \n\n[ %{А%}:я | %{Ы%}:и ] &lt;=&gt; %{j%}:0 _ ;\n```\n\n\n```{twol}\nAlphabet\n  а и м н п я Т\n  %{А%}:а %{А%}:я %{Ы%}:ы %{Ы%}:и %{j%}:0;\n\nRules\n\n\"удаляем маркер мягкой основы\" \n\n%{j%}:0 &lt;=&gt; _ ;\n\n\"гласные после мягкой основы в номинативе\" \n\n%{А%}:я &lt;=&gt; %{j%}:0 _ ;\n\n\"гласные после мягкой основы в генетиве\" \n\n%{Ы%}:и &lt;=&gt; %{j%}:0 _ ;\n```\n\n\n\n\nОператор & имеет семантику ‘и’, что в данном случае будет вызывать пересечение множеств\n\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot\n\nLEXICON Root\naa \nba \nla \nma \nxa \nya \nza\n```\n\n\n```{twol}\nAlphabet\n    a b l m x y z a:b;\n\nSets\n    X = x y z;\n    Y =   y z l m;\n\nRules\n\n\"change\"\na:b &lt;=&gt; X & Y _;\n```\n\n\naa\nba\nxa      # есть в X\nya:yb   # есть и в X, и Y\nza:zb   # есть и в X, и Y\nla      # есть в Y\nma      # есть в Y\n\n\n\n\nОператор - имеет семантику ‘без’, что в данном случае будет вызывать разность множеств\n\n\nlexdtwolрезультат\n\n\n```{lexd}\nPATTERNS\nRoot\n\nLEXICON Root\naa \nba \nla \nma \nxa \nya \nza\n```\n\n\n```{twol}\nAlphabet\n    a b l m x y z a:b;\n\nSets\n    X = x y z;\n    Y =   y z l m;\n\nRules\n\n\"change\"\na:b &lt;=&gt; X - Y _;\n```\n\n\naa\nba\nxa:xb   # есть в X\nya      # есть и в X, и Y\nza      # есть и в X, и Y\nla      # есть в Y\nma      # есть в Y\n\n\n\n\n\n\n\n\n\nЗадание 03_03\n\n\n\nЗаполните раздел правил в файле .twol ниже, чтобы получившийся трансдьюсер моделировал образование сравнительной степени в английском (германские, индоевропейские), например, big - bigger:\n\nlexdtwol\n\n\n```{lexd}\nPATTERNS\nRoot Infl\n\nLEXICON Root\nbig\nhot\nsad\nthin\nwet\n# group 2\nbright\ncheap\ncold\ndeep\nhard\nhigh\nold\nrich\nsmall\nslick\nsoft\ntall\n\nLEXICON Infl\n&lt;comp&gt;:{comp}er\n```\n\n\n```{twol}\nAlphabet\n    a b c d e f g h i j k l m n o p q r s t u v w x y z\n    0:g 0:t 0:d 0:n\n    %{comp%}:0;\n\nSets\n    Vowels = a e i o u y;\n\nRules\n\n\"геминация\"\n\n\n\"гиперфонема для морфологии\"\n\n\n```\n\n\n\n\n\n\n\n3.3.8 Операторы правил\nСуществует 4 оператора правил, однако на практике вам чаще всего понадобиться только первый. В (Beesley и Karttunen 2003) даются следующие определения этим операторам:\n\na:b &lt;=&gt; l _ r ;\n\nPositive Reading 1: Если появляется пара a:b, то она должна быть в контексте l _ r.\nNegative Reading 1: Если пара a:b появляется вне контекста l _ r, программа выдает ошибку.\nPositive Reading 2: Если глубинное a появляется в контексте l _ r, тогда оно должно быть реализовано на поверхностном уровне как b.\nNegative Reading 2: Если глубинное a появляется в контексте l _ r и реализуется на поверхностном уровне чем-то кроме как b, программа выдает ошибку.\n\na:b =&gt; l _ r ;\n\nPositive Reading: Если появляется пара a:b, то она должна быть в контексте l _ r.\nNegative Reading: Если пара a:b появляется вне контекста l _ r — останавливайся.\n\na:b &lt;= l _ r ;\n\nPositive Reading: Если глубинное a появляется в контексте l _ r, тогда оно должно быть реализовано на поверхностном уровне как b.\nNegative Reading: Если глубинное a появляется в контексте l _ r и реализуется на поверхностном уровне чем-то кроме как b, программа выдает ошибку.\n\na:b /&lt;= l _ r ;\n\nPositive Reading: Глубинное а никогда не может быть реализовано на поверхностном уровне как b в контексте l _ r\nNegative Reading: Если глубинное а реализовано на поверхностном уровне как b в контексте l _ r, программа выдает ошибку.\n\n\nНиже приводится таблица из (Beesley и Karttunen 2003), которая иллюстрирует поведение операторов:\n\n\n\n\n\n\n\n\n\n\nоператор\nпример 1\nпример 2\nпример 3\nпример 4\n\n\n\n\na:b &lt;=&gt; l _ r;\nlar:lbr\nlar:lar\nlbr:lbr\nxay:xby\n\n\na:b =&gt; l _ r;\nlar:lbr\nlar:lar\nlbr:lbr\nxay:xby\n\n\na:b &lt;= l _ r;\nlar:lbr\nlar:lar\nlbr:lbr\nxay:xby\n\n\na:b /&lt;= l _ r;\nlar:lbr\nlar:lar\nlbr:lbr\nxay:xby\n\n\n\nВ большинстве случаев нужно использовать оператор &lt;=&gt;. Потребность в других операторах возникает только если есть конфликтующие правила.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html#глоссирование",
    "href": "03_phonological_rules.html#глоссирование",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "3.4 Глоссирование",
    "text": "3.4 Глоссирование\nВсе это время анализ, который мы получали, содержал исключительно грамматические теги без морфемных границ. Основной разработчик парадигмы правилового морфологического анализа — Apertium — скорее заинтересован в создании переводчиков, поэтому морфемные границы отходят на второй план. Однако ожидание большинства лингвистов все же заключается в том, что морфемные границы в анализе должны быть, так как для них нет другой мотивации вкладываться в работу над морфологическим анализатором, кроме как если у них есть множество неотглоссированных текстов, которые они не хотят глоссировать вручную.\nПолучается так:\n\nНа вход мы подаем текст на языке.\nНа выходе мы получаем множество пар, где каждый элемент это\n\nанализ с поморфемной разбивкой;\nматериал на языке с поморфемной разбивкой.\n\n\nОтметим, что морфологическая граница традиционно в таких случаях обозначается &gt;. Это не самый удобный для читаемости символ, но его ожидают разные другие полезные инструменты на основе трансдьюсеров. Если мы хотим разработать инструмент для глоссироваания, нам имеет смысл создать два похожих трансдьюсера:\n\nwalk&gt;s — walk&lt;v&gt;&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;\nwalks — walk&lt;v&gt;&gt;&lt;pres&gt;&lt;3&gt;&lt;sg&gt;\n\nОдин от другого отличается одним правилом в twol.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html#мысли-в-сторону",
    "href": "03_phonological_rules.html#мысли-в-сторону",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "3.5 Мысли в сторону",
    "text": "3.5 Мысли в сторону\nВажно отметить, что twol отлично помогает моделировать переходы от глубинного представления в поверхностное, что помогает моделировать (мор)фонологию. Однако не стоит считать двухуровневую фонологию фонологической теорией. Она разрабатывалась прежде всего для практических нужд, а в таком случае все средства хороши. Правила двухуровневой фонологии часто слишком языкоцентричны, и поэтому сложно перейти от них к некоторым обобщениям. Кроме того, отказ от последовательности правил приводит к тому, что получившиеся правила двухуровневой фонологии часто неестественны, так как вынуждены включать в себя работу сразу всех (мор)фонологических процессов языка.\n\n\n\n\nBeesley, K. R., и L. Karttunen. 2003. «Two-level rule compiler».\n\n\nChomsky, N., и M. Halle. 1968. The sound pattern of English. New York, Evanstone, London: Haper & Row.\n\n\nJohnson, C. D. 1972. Formal aspects of phonological description. The Hague, Paris: Mouton.\n\n\nKiparsky, P. 1982 (1968). «Linguistic universals and linguistic change». В Explanation in Phonology, под редакцией P. Kiparsky. Dordrecht, Cinnaminson: Foris Publications.\n\n\nKoskenniemi, K. 1983. «Two-level morphology: A general computational model for word-form recognition and production». Phdthesis, University of Helsenki, Department of General Linguistics.\n\n\nPrince, A., и P. Smolensky. 1994. «Optimality Theory: Constraint interaction in generative grammar». Rutgers University, Piscataway, NJ., Rutgers Center for Cognitive Science.\n\n\nАркадьев, П. М., Ю. А. Ландер, А. Б. Летучий, Н. Р. Сумбатова, и Я. Г. Тестелец. 2009. «Введение. Основные сведения об адыгейском языке». В Аспекты полисинтетизма: очерки по грамматике адыгейского языка, 17–120.\n\n\nИткин, И. Б. 2007. Русская морфонология. Москва: Гнозис.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "03_phonological_rules.html#footnotes",
    "href": "03_phonological_rules.html#footnotes",
    "title": "3  Введение в twol: (мор)фонология",
    "section": "",
    "text": "Вот пример питающего порядка из бразильского португальского (индоевропейские).\n\n\n\nправило\nформа\nтранскрипция\nглосса\n\n\n\n\nпалатализация\nbato\n[bátu]\nбить-1sg\n\n\nпалатализация\nbate\n[bátʃi]\nбить-3sg\n\n\nпалатализация\nardo\n[áɾdu]\nжечь-1sg\n\n\nпалатализация\narde\n[áɾdʒi]\nжечь-3sg\n\n\nэпентеза i\npacto\n[pákitu]\nсоглашение\n\n\nэпентеза i\ncaptar\n[kapitáɾ]\nвзять в плен\n\n\nэпентеза i\npsicologia\n[pisikoloʒíɐ]\nпсихология\n\n\n\nА вот взаимодействие правил:\n\n\n\n\n\n\n\n\n\n\n\n/kaptáɾ/  взять в плен\n/áɾdi/  жечь-3sg\n/advɛ́χsu/  враждебный\n/futbɔ́w/  футбол\n\n\n\n\nэпентеза I\nkapitáɾ\n—\nadivɛ́χsu\nfutibɔ́w\n\n\nпалатализация\n—\náɾdʒi\nadʒivɛ́χsu\nfutʃibɔ́w\n\n\n\n↩︎\nВот пример питающего порядка из литовского (индоевропейские).\n\n\n\nправило\nтранскрипция\nперевод\n\n\n\n\nэпентеза i\n[at-koːpʲtʲi]\nприйти\n\n\nэпентеза i\n[atʲi-tʲeisʲtʲi]\nприсудить\n\n\nэпентеза i\n[ap-kalʲbʲetʲi]\nоговорить\n\n\nэпентеза i\n[apʲi-putʲi]\nподгнить\n\n\nозвончение\n[at-praʃʲiːtʲi]\nспросить\n\n\nозвончение\n[ad-gautʲi]\nвернуть\n\n\nозвончение\n[ap-ʃaukjtji]\nобъявить\n\n\nозвончение\n[ab-gautji]\nобмануть\n\n\n\nА вот взаимодействие правил:\n\n\n\n\n\n\n\n\n\n\n\n/ap-putʲi/  подгнить\n/at-gautʲi/  вернуть\n/at-duotʲi/  отдать\n/ap-bʲekʲtʲi/  обежать\n\n\n\n\nэпентеза i\napʲi-putʲi\n—\natʲi-duotʲi\napʲi-bʲekʲtʲi\n\n\nозвончение\n—\nad-gautʲi\n—\n—\n\n\n\n↩︎\nЕсли удалить из работающего файла одно из названий правила получится ошибка, в которой самым явным будет часть сообщения Error: twol.hfst is not a valid transducer file.↩︎\nЭтот термин предложил Н. С. Трубецкой для единиц, находящихся в слабой фонологической позиции и характеризующихся неполным набором признаковых спецификаций (например, оглушение на конце слова в русском). Однако в практике пользователей lexd и twol архифонемы — это просто единицы удобные для моделирования. Иногда их используют и для случаев подразумевавшихся Трубецким, например, для моделирования гармонии, но иногда их используют для моделирования других морфонологических сложностей.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Введение в `twol`: (мор)фонология</span>"
    ]
  },
  {
    "objectID": "04_language_tasks.html",
    "href": "04_language_tasks.html",
    "title": "4  Моделирование языковых явлений",
    "section": "",
    "text": "4.1 Амбификсы",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Моделирование языковых явлений</span>"
    ]
  },
  {
    "objectID": "04_language_tasks.html#амбификсы",
    "href": "04_language_tasks.html#амбификсы",
    "title": "4  Моделирование языковых явлений",
    "section": "",
    "text": "Задание 04_01\n\n\n\nСмоделируйте при помощи lexd и twol поведение литовского возвратного суффикса -si, который занимает позицию перед корнем, если к нему присоединяется какой-либо префикс.\n\n\n\nперевод\nroot-inf-rfl\nneg-rfl-root-inf\n\n\n\n\nучиться\nmoky-ti-s\nne-si-moky-ti\n\n\nрадоваться\ndžiaug-ti-s\nne-si-džiaug-ti\n\n\nосматриваться\nžvalgy-ti-s\nne-si-žvalgy-ti\n\n\nгордиться\ndidžiuo-ti-s\nne-si-didžiuo-ti\n\n\nсмеяться\njuok-ti-s\nne-si-juok-ti",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Моделирование языковых явлений</span>"
    ]
  },
  {
    "objectID": "04_language_tasks.html#кабардинское-глагольное-согласование",
    "href": "04_language_tasks.html#кабардинское-глагольное-согласование",
    "title": "4  Моделирование языковых явлений",
    "section": "4.2 Кабардинское глагольное согласование",
    "text": "4.2 Кабардинское глагольное согласование\n\n\n\n\n\n\nЗадание 04_02\n\n\n\nМы составили на основе (Кумахов и др. 2006: 169–179) (и с помощью Ю. А. Ландера) фрагмент парадигмы глагола ‘идти’1 в кабардино-черкесском языке (абхазо-адыгские, адыгские). В таблице приводятся поверхностная и глубинные формы. Смоделируйте приведенные формы, используя lexd и twol. Графема у обозначает в данном примере лабиализацию [ʷ] или комбинацию губного аппроксиманта и ы [wə]. При моделировании не следует соединять в одной форме префикс дериктива &lt;dir&gt; и аппликативов (&lt;com&gt;, &lt;ben&gt;, &lt;mal&gt;). В кабардино-черкесском языке это возможно, но требует дополнительной морфонологии. Алфавит: а б в д з к н о п с т у ф х щ ъ ы э I.\n\n\n\n\n\n\n\n\n\n\n\n\nКумахов, М. А., М. Л. Апажев, З. Х. Бижева, Б. Ч. Бижоев, Дж. Н. Коков, Х. Т. Таов, и Р. Х. Темирова. 2006. «Кабардино-черкесский язык в двух томах».",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Моделирование языковых явлений</span>"
    ]
  },
  {
    "objectID": "04_language_tasks.html#footnotes",
    "href": "04_language_tasks.html#footnotes",
    "title": "4  Моделирование языковых явлений",
    "section": "",
    "text": "Стоит иметь ввиду, что комитативные формы от данного глагола чаще употребляются не в буквальном значении, а в значении “выйти замуж”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Моделирование языковых явлений</span>"
    ]
  },
  {
    "objectID": "05_technical_class.html",
    "href": "05_technical_class.html",
    "title": "5  Технические детали: командная строка, инструменты hfst",
    "section": "",
    "text": "5.1 Командная оболочка\nКогда вы открываете линуксовскую командную строку, чаще всего вы сталкиваетесь с интерпретатором bash –– это командная оболочка, которая позволяет отдавать команды вашей операционной системе и компьютеру. В данных материалах мы используем обобщенное shell, включающее в себя разные командные оболочка. Так как обычно команды в командной строке исполняются сразу, знак доллара традиционно используют для обозначения строчки с командой:\nРазумеется, когда дело доходит до больших и сложных программ, то их записывают в скрипты, которым обычно дают расширение .sh и начинают с шебанга. Вот пример простой программы:\nЕсли записать эту программу в файл my_script.sh, то ее потом можно запустить следующей командой:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Технические детали: командная строка, инструменты `hfst`</span>"
    ]
  },
  {
    "objectID": "05_technical_class.html#командная-оболочка",
    "href": "05_technical_class.html#командная-оболочка",
    "title": "5  Технические детали: командная строка, инструменты hfst",
    "section": "",
    "text": "```{shell}\n$ echo \"hi all\"\n\nhi all\n```\n\n#!/bin/bash\n\necho \"Please enter your name: \"\nread name\necho \"Nice to meet you $name\"\n\n```{shell}\n$ sh my_script.sh\n```",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Технические детали: командная строка, инструменты `hfst`</span>"
    ]
  },
  {
    "objectID": "05_technical_class.html#программы-для-команадной-строки",
    "href": "05_technical_class.html#программы-для-команадной-строки",
    "title": "5  Технические детали: командная строка, инструменты hfst",
    "section": "5.2 Программы для команадной строки",
    "text": "5.2 Программы для команадной строки\nДля командной строки написано очень много разных программ. Важно понимать, что их все (естественно, после установки, если это необходимо) можно запустить, набрав в консоли название программы. Начнем наше знакомство с программы ls, которая перечисляет (list) содержание папок:\n```{shell}\n$ ls\n\n01_00_stemmers.png                  01_09_first_transducer.png\n01_01_light_switch.jpg              01_10_morphology.png\n01_02_light_switch_automaton.png    01_11_transducer_composition.png\n01_03_turnstile.jpg                 01_12_morphology2.png\n01_04_turnstile_automaton.png       03_01_Russita-feeding.png\n01_05_elephant.png                  03_02_Russita-bleeding.png\n01_06_elephant_short.png            03_03_Russita-counterfeeding.png\n01_07_multiple_words.png            03_04_Russita-counterbleeding.png\n01_08_multiple_words_optimized.png\n```\nУ большинства программ есть некоторые аргументы (почему-то их принято называть флагами), которые перечисляют после минуса.\n```{shell}\n$ ls -l\n\ntotal 2636\n-rw-rw-r-- 1 agricolamz agricolamz 122183 Jan  6 18:52 01_00_stemmers.png\n-rw-rw-r-- 1 agricolamz agricolamz 121071 Feb 18  2022 01_01_light_switch.jpg\n-rw-rw-r-- 1 agricolamz agricolamz 156956 Jan  6 07:45 01_02_light_switch_automaton.png\n-rw-rw-r-- 1 agricolamz agricolamz  18075 Feb 18  2022 01_03_turnstile.jpg\n-rw-rw-r-- 1 agricolamz agricolamz 167801 Jan  6 07:47 01_04_turnstile_automaton.png\n-rw-rw-r-- 1 agricolamz agricolamz 200090 Jan  6 07:50 01_05_elephant.png\n-rw-rw-r-- 1 agricolamz agricolamz 106598 Jan  6 07:51 01_06_elephant_short.png\n-rw-rw-r-- 1 agricolamz agricolamz 226555 Jan  6 07:52 01_07_multiple_words.png\n-rw-rw-r-- 1 agricolamz agricolamz 139834 Jan  6 07:58 01_08_multiple_words_optimized.png\n-rw-rw-r-- 1 agricolamz agricolamz 132286 Jan  6 16:02 01_09_first_transducer.png\n-rw-rw-r-- 1 agricolamz agricolamz 117095 Jan  6 17:15 01_10_morphology.png\n-rw-rw-r-- 1 agricolamz agricolamz 253314 Jan  6 18:32 01_11_transducer_composition.png\n-rw-rw-r-- 1 agricolamz agricolamz 261112 Jan 12 18:20 01_12_morphology2.png\n-rwxr-xr-x 1 agricolamz agricolamz 159091 Jan 13  2017 03_01_Russita-feeding.png\n-rwxr-xr-x 1 agricolamz agricolamz 150034 Jan 13  2017 03_02_Russita-bleeding.png\n-rwxr-xr-x 1 agricolamz agricolamz 140454 Jan 13  2017 03_03_Russita-counterfeeding.png\n-rwxr-xr-x 1 agricolamz agricolamz 193216 Jan 13  2017 03_04_Russita-counterbleedin\n```",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Технические детали: командная строка, инструменты `hfst`</span>"
    ]
  },
  {
    "objectID": "05_technical_class.html#компеляция-трансдьюсеров",
    "href": "05_technical_class.html#компеляция-трансдьюсеров",
    "title": "5  Технические детали: командная строка, инструменты hfst",
    "section": "5.3 Компеляция трансдьюсеров",
    "text": "5.3 Компеляция трансдьюсеров\nТеперь попробуем шаг за шагом скомпилировать наш морфологический трансдьюсор, используя программы lexd и hfst-twolc.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Технические детали: командная строка, инструменты `hfst`</span>"
    ]
  },
  {
    "objectID": "05_technical_class.html#другие-инструменты-hfst",
    "href": "05_technical_class.html#другие-инструменты-hfst",
    "title": "5  Технические детали: командная строка, инструменты hfst",
    "section": "5.4 Другие инструменты hfst",
    "text": "5.4 Другие инструменты hfst",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Технические детали: командная строка, инструменты `hfst`</span>"
    ]
  },
  {
    "objectID": "06_transducer_manipulation.html",
    "href": "06_transducer_manipulation.html",
    "title": "6  Операции с трансдьюсерами",
    "section": "",
    "text": "6.1 Создание транслитераторов",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Операции с трансдьюсерами</span>"
    ]
  },
  {
    "objectID": "06_transducer_manipulation.html#вычитание-трансдьюсеров",
    "href": "06_transducer_manipulation.html#вычитание-трансдьюсеров",
    "title": "6  Операции с трансдьюсерами",
    "section": "6.2 Вычитание трансдьюсеров",
    "text": "6.2 Вычитание трансдьюсеров",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Операции с трансдьюсерами</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Список литературы",
    "section": "",
    "text": "Arefyev, N. V., T. Y. Gratsianova, and K. P. Popov. 2018.\n“Morphological Segmentation with Sequence to Sequence Neural\nNetwork.” In KКомпьютерная Лингвистика и Интеллектуальные\nТехнологии, 85–95.\n\n\nBeesley, K. R., and L. Karttunen. 2003a. Finite State Morphology:\nXerox Tools and Techniques. Stanford: Center for Study of Language\nInformation.\n\n\n———. 2003b. “Two-Level Rule Compiler.”\n\n\nBolshakova, E. I., and A. S. Sapin. 2019a. “Bi-LSTM Model for\nMorpheme Segmentation of Russian Words.” In Artificial\nIntelligence and Natural Language: 8th Conference, AINL 2019, Tartu,\nEstonia, November 20–22, 2019, Proceedings 8, 151–60. Springer.\n\n\n———. 2019b. “Comparing Models of Morpheme Analysis for Russian\nWords Based on Machine Learning.” In Компьютерная Лингвистика\nи Интеллектуальные Технологии, 104–13.\n\n\n———. 2020. “An Experimental Study of Neural Morpheme Segmentation\nModels for Russian Word Forms.” In CMCL, 79–89.\n\n\nChomsky, N., and M. Halle. 1968. The Sound Pattern of\nEnglish. New York, Evanstone, London: Haper & Row.\n\n\nGaripov, T., D. Morozov, and A. Glazkova. 2023. “Generalization\nAbility of CNN-Based Morpheme Segmentation.” In 2023\nIvannikov Ispras Open Conference (ISPRAS), 58–62. IEEE.\n\n\nGrönroos, S.-A., S. Virpioja, P. Smit, and M. Kurimo. 2014.\n“Morfessor FlatCat: An\nHMM-Based Method for Unsupervised and Semi-Supervised\nLearning of Morphology.” In Proceedings of COLING 2014, the\n25th International Conference on Computational Linguistics: Technical\nPapers, 1177–85.\n\n\nJohnson, C. D. 1972. Formal Aspects of Phonological\nDescription. The Hague, Paris: Mouton.\n\n\nKarlsson, F. 2013. Finnish: An Essential Grammar. Routledge.\n\n\nKiparsky, P. 1982 (1968). “Linguistic Universals and Linguistic\nChange.” In Explanation in Phonology, edited by P.\nKiparsky. Dordrecht, Cinnaminson: Foris Publications.\n\n\nKoskenniemi, K. 1983. “Two-Level Morphology: A General\nComputational Model for Word-Form Recognition and Production.”\nPhD thesis, University of Helsenki, Department of General Linguistics.\n\n\nLindén, K., E. Axelson, S. Hardwick, T. A. Pirinen, and M. Silfverberg.\n2011. “Hfst—Framework for Compiling and Applying\nMorphologies.” In Systems and Frameworks for Computational\nMorphology: Second International Workshop, SFCM 2011, Zurich,\nSwitzerland, August 26, 2011. Proceedings 2, 67–85. Springer.\n\n\nMealy, G. H. 1955. “A Method for Synthesizing Sequential\nCircuits.” The Bell System Technical Journal 34 (5):\n1045–79.\n\n\nMoore, E. F. 1956. “Gedanken-Experiments on Sequential\nMachines.” Automata Studies 34: 129–53.\n\n\nOrtiz Rojas, S., M. L. Forcada, and G. Ramı́rez Sánchez. 2005.\n“Construcción y Minimización Eficiente\nde Transductores de Letras a Partir de Diccionarios Con\nParadigmas.” Procesamiento Del Lenguaje Natural 35:\n51–57.\n\n\nPrince, A., and P. Smolensky. 1994. “Optimality Theory: Constraint\nInteraction in Generative Grammar.” Rutgers University,\nPiscataway, NJ., Rutgers Center for Cognitive Science.\n\n\nSingh, J., and V. Gupta. 2017. “A Systematic Review of Text\nStemming Techniques.” Artificial Intelligence Review 48:\n157–217.\n\n\nSorokin, Alexey, and Anastasia Kravtsova. 2018. “Deep\nConvolutional Networks for Supervised Morpheme Segmentation of Russian\nLanguage.” In Artificial Intelligence and Natural Language:\n7th International Conference, AINL 2018, St. Petersburg, Russia, October\n17–19, 2018, Proceedings 7, 3–10. Springer.\n\n\nStraka, Milan. 2018. “UDPipe 2.0 Prototype at CoNLL\n2018 UD Shared Task.” In Proceedings of the\nCoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal\nDependencies, 197–207.\n\n\nSumbatova, N. R., and R. O. Mutalov. 2003. A Grammar of\nItsari Dargwa. Muenchen: Lincom Europa.\n\n\nSwanson, D., and N. Howell. 2021. “Lexd: A Finitestate Lexicon\nCompiler for Non-Suffixational Morphologies.” In Multilingual\nFacilitation, 133–46.\n\n\nWintner, S. 2008. “Strengths and Weaknesses of Finite-State\nTechnology: A Case Study in Morphological Grammar Development.”\nNatural Language Engineering 14 (4): 457–69.\n\n\nАркадьев, П. М., Ю. А. Ландер, А. Б. Летучий, Н. Р. Сумбатова, and Я. Г.\nТестелец. 2009. “Введение. Основные Сведения Об Адыгейском\nЯзыке.” In Аспекты Полисинтетизма: Очерки По Грамматике\nАдыгейского Языка, 17–120.\n\n\nАрхангельский, Т. А. 2012. “Принципы Построения Морфологического\nПарсера Для Разноструктурных Языков.” PhD thesis, Московский\nгосударственный университет им. М. В. Ломоносова.\n\n\nИткин, И. Б. 2007. Русская Морфонология. Москва: Гнозис.\n\n\nКумахов, М. А., М. Л. Апажев, З. Х. Бижева, Б. Ч. Бижоев, Дж. Н. Коков,\nХ. Т. Таов, and Р. Х. Темирова. 2006. “Кабардино-Черкесский Язык в\nДвух Томах.”\n\n\nРогава, Г. В., and З. И. Керашева. 1966. Грамматика Адыгейского\nЯзыка. Майкоп, Краснодар: Краснодарское книж. издательство.",
    "crumbs": [
      "Список литературы"
    ]
  }
]